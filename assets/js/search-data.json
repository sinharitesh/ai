{
  
    
        "post0": {
            "title": "List Of Projects",
            "content": "DATA SCIENCE PROJECTS . Deep Learning - Image Recognition . Application of Transfer Learning in various use cases. Currently working on detecting diseases in an XRay by using Resnet architecture and fine tuning with provided dataset. Productionizing models on AWS Lambda platform and using Python starlette package. Have successfully applied transfer learning on Geospatial images and finding existence of various objects. . Technical Environment: Pytorch, Fastai, AWS . Vibration Data Analysis and Condition Monitoring . Merck, Inc. . Condition monitoring by analysis of Vibration data for determining the health of a device. Time waveform, Spectrum Analysis, Fourier Transform are some of the techniques used here. Designing rules based on statistical considerations such as movement of orders, persona changes, etc. Setting up the architecture for scaling of Fault Detection, interpretation of faults, etc. Further suggested and developed framework for predictive models to determine the probability of failure of a component. . Technical Environment: RStudio, dplyr, ggplot2, plotly, postgres . Natural Language Processing – Financial Modeling . Prediction of alpha based on sentiment and stock price movement data. Processing of financial articles and determining sentiments attached to it, using NLTK library (sentient and vader). External sentiment data was correlated with Stock movement data and subsequently, machine learning models were built. These models were made accessible using Flask in Python. Also a search mechanism was developed using TF-IDF models and cosine similarity scores. Given a stock and sentiment polarity, most relevant articles related to stocks are found. Models created were operationalized with help of the Flask library available in python. . Technical Environment: Python, NLTK, Flask . Cummins Inc - Data Science . Cummins Inc has worked on data science initiatives to bring down costs related to repair and maintenance. I have set up the data pipeline which reads data from various tables and creates a single dataset which helps in building machine learning models to determine probability of component failure given a symptom and service model name. This helps in maintaining appropriate stock at various warehouses. . Second use case is to find the reasons for repeated visits. Repeated visits are a source of revenue impact as warranty is breached when an engine comes for repair within a month of earlier visit. This is a data discovery exercise where I am writing R Script to generate a dataset which contains reason, symptoms related to a repeated visit and find probable causes. . Internet of Things . Worked on a number of RFPs related to Data Science proposals. Proposed the usage of Weibull distribution and others to estimate the life of complex equipment like Power Transformers. . Worked as a data scientist on an anomaly detection offering for various use cases. Worked on Chiller Plant (HVAC) data to identify anomalies. . Worked on a pilot for Manufacturing client to gather insights from data using exploratory data analysis. This was targeted to identify production lines with good OEE (Overall Equipment Efficiency) and ways to maximize it. . Designed a predictive maintenance solution around Aircraft maintenance. Data Science related use case was defined, designed and executed by me using the R Statistical Package. This demo has been presented in International Airshow at Farnborough, UK. . Designed an IOT Solution for connected devices. This project consists of developing a generic simulator and designing the interface for connected products. Implemented predictive analytics by applying machine learning on machine and asset related data, batch alerts using R. The connected products solution has been developed in a way that it can cater to a number of domains and clients. Have participated in creating demos for a number of clients. . Implemented Predictive maintenance for Connected Products using R Programming language for condition monitoring. Combined device and asset data to create a labeled dataset which was later used to determine probability of failure of a component in the next fifteen days. . Technical Environment: R Programming Language, Python, IBM Bluemix, IOT Foundation, Node JS, Azure MLStudio. . Building Big Data Analytic Pipeline . Worked as Senior Technical Architect on designing an Analytics pipeline for real time streaming with device data. . Technologies used are R Programming Language, Spark Streaming, Spark Machine Learning libraries. Also, building various models, such as Decision Tree Model, Random Forest model for implementing various use cases related to IoT. . Technical Environment: Scala, Spark, Hadoop and Kafka. . Telecom Analytics . Worked as a Data Scientist with Big Data Analytics. This profile required planning and execution of various proof of concepts related to analytics, such as fraud detection, roaming analytics, etc. . Have worked on a PoC for identifying fraud related to Simbox. This required feature generation from existing call detail records and then identifying fraudulent machine and sim ids. . Have worked on CRM records and Voice and SMS data for identification of silent roamers and provide recommendations for increase in revenue. . Worked on a PoC for reducing the revenue loss for premium numbers. This PoC requires in correctly identifying the users likely to default. . Tools - Hadoop, Mapreduce, Tableau and R (including ggplot). . I-Analytics . This project was undertaken to build various statistical models using the concepts of statistics and machine learning (Random forests, K-Means Clustering, Logistic regression). . These models have been developed to address a variety of use cases including: . Designing a sentiment mining system by applying Naïve Bayes principles. . Development of use cases and Analysis of crime related data. . Development of a multivariate predictive model for doing spend analysis. . Development of use cases for using Hadoop as an archival tool. . Role: Designing Data Science related implementation, create machine learning models. . Responsibilities: . Analysis of data using standard statistical models (linear regression) and machine learning concepts (K means, Random Forests, etc.) . Planning and executing POCs. . Resource mentoring on Big Data and Analytics. . Tools : R, Hadoop, Hive, Pig. . Project – I-Port . This project has been initiated to develop a product I-Port whose aim is to create a dashboard and incorporate forecasting models leveraging Big Data and advanced analytics.This product has the capability to provide a single view of the organizational processes and their performances., A number of KPIs have been developed using various technologies. . Creation of BI dashboard for BPO processes for various KPIs. These include Fraud chargebacks, Call volume, calls trend, etc. Development of predictive models for calls and complaints. Qlikview design and development of complex dashboards and reporting. . Developing forecasting models (uni and multivariate) using R. Implementation of forecasts on a dashboard. . Designing a model for doing sentiment analysis (location specific) using twitter. . Developing the architectural solution involving Hadoop (hive) and Qlikview. . Role: Data Analyst/ Consultant. . Responsibilities: . Developing the technical architecture of the product. Evaluating Big Data and open source technologies and building the proof of concept. . Development of forecasting model for predicting volume of calls (using Pig and R). . Writing PIG/Mapreduce programs for summarizing the data. . Designing a model of sentiment analysis using twitter data. . Achievements: . This product (developed in house) has addressed the need of having a dashboard with predictive capabilities. This solution has used Big Data technologies thus building organizational capability. . Developing a BI dashboard using Qlikview with no prior capability. This is a fully deployed solution in Qlikview using SAP extracts and Qlikview 11. . Environment: MySQL, Talend, Pentaho, Hadoop, Pig, R (Regression), Qlikview. . EMPLOYMENT SUMMARY . Pentair Water India Ltd Feb 2022 - Till Date . HCL Technologies Limited May 2015 - Feb 2022 . Mobileum India P. Ltd. Sep 2014 - Jan 2015 . Steria India Ltd. Aug 2004 - Sep 2014 . Perot Systems Feb 2003 - Jul 2004 . TCG Software Services Pvt Ltd Jul 1998 - Feb 2003 .",
            "url": "https://sinharitesh.github.io/ai/2022/04/15/List-of-Projects.html",
            "relUrl": "/2022/04/15/List-of-Projects.html",
            "date": " • Apr 15, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://sinharitesh.github.io/ai/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://sinharitesh.github.io/ai/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://sinharitesh.github.io/ai/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://sinharitesh.github.io/ai/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}